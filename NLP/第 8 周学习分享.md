时间：2019年5月13日 ~ 2019年5月19日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
段金强 | 学习 梅尔倒频谱系数（MFCC） | 梅尔倒频谱系数（Mel Frequency Cepstral Coefficents ,MFCC）：它是自动识别语音的的一个预处理步骤，目的是提取语音特征。简单说就是通过对音频的分析，把信号中的辨识性的成分提出出来（例如：音色），把噪音，背景声音去掉。处理过程：1、先对语音进行预加重、分帧和加窗；预加重:在语音信号中，高频部分的能量一般比较低，信号不利于处理，提高高频部分的能量能更好的处理；分帧：在比较短的时间内，语音信号不会发生突变，利于处理，例如：信号的采样频率为 16kHz，每一帧切分为25ms， 那么每一帧有400个采样点。如果帧数不为偶数，通常还要padding；加窗：帧内信号在后序FFT（傅里叶变换）变换的时候不会出现端点突变的情况，较好地得到频谱；2、将每一帧通过FFT得到对应的频谱；3、将上面的频谱通过Mel滤波器组得到Mel频谱；4、在Mel频谱上面进行倒谱分析（取对数，做逆变换，实际逆变换一般是通过DCT离散余弦变换来实现，取DCT后的第2个到第13个系数作为MFCC系数），获得Mel频率倒谱系数MFCC，这个MFCC就是这帧语音的特征；
任星凯 | 复习数学考试，做百度阅读理解比赛 | 这周主要在复习数学考试，剩下的时间大多投入了百度阅读理解比赛中，尝试了tencent中文词向量
李昌群 | Pointer-network | 传统的注意力机制，通过softmax操作得到权重矩阵，依据该权重求加权和，然后把得到的拼接（或者加和）到decoder的隐状态上，最后让decoder部分根据拼接后新的隐状态进行解码和预测。Pointer Networks直接将softmax之后得到的当成了输出，让承担指向输入序列特定元素的指针角色。<br />Pointer Networks，得到预测结果的方式便是输出一个概率分布，也即所谓的指针。换句话说，传统带有注意力机制的seq2seq模型输出的是针对输出词汇表的一个概率分布，而Pointer Networks输出的则是针对输入文本序列的概率分布。 
夏鑫林 | 学习了GAN | 由于近期关注推荐系统等方面比较多，而这个领域前沿的跟GAN相关度比较大，所以上周学习了李宏毅的GAN
王耿鑫 | skip-gram softmax 优化方法 | skip-gram 直接 softmax 太慢了，有两种常用的优化方法：<br />1. 分层 softmax：<br />我们根据词频建立一个霍夫曼树，对于高频的词汇，会出现在相对较浅的叶子节点，而低频词汇会出现在相对深的叶子节点，可以优化计算效率。在训练的时候，对于一个给定的词，我们只需要计算约 O(logV) 次逻辑回归二分类就可以了，这样就可以大大提高计算效率。而这个词的概率等于路径上各个二分类的概率的乘积。<br />2. 负采样<br />我们除了构造正例，还构造负例。对于一段文本，我们从中选出一个词来作为上下文词，然后在窗口范围内再随机选另一个词作为目标词，这样就构成了一对正例。此时，我们再从字典里随机取 K 个词，这 K 个词分别和上下文词构成负例。这样，我们就得到了 K+1 个词对作为训练数据。然后呢，对于输出层，我们不再使用 softmax，而是用 V 个二分类器来代替(V是词汇表大小)。每次迭代训练的时候，我们只需要训练 K+1 个二分类器就可以了。 

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
