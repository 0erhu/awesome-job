时间：2019年7月15日 ~ 2019年7月21日

| 学习人  | 学习任务   | 学习心得和参考资料                                |
| ---- | ------ | ---------------------------------------- |
| 段金强  | 总结项目经验 | 这周没有看算法，暂时没想好看哪种，总结一下过去几周一个项目的经验。 1、立项阶段，充分了解项目的流程和业务（越详细越好，这块需要花一定的时间），这一块做的是否好，决定了以后的研发速度和研发质量。 2、需求确认阶段，这块是根据对方的业务需求和己方具体承担哪些任务，要充分沟通和确认（越具体越好，最好具体到每个字段的含义），以免后面返工，扯皮。 3、研发阶段，先有优秀的研发人员或架构师对业务的框架进行搭建（最好也和研发人员普及，解释原由和优缺点，框架上达成一致，方便后面的开发），研发人员的好坏也决定了项目的进度和质量。当然最好有一个需求人员实时和业务和研发对接，沟通。如果需求变更要书面记录（很重要）。 4、测试阶段，当然一边研发一边测试，最好分批进行，一是为了检验研发的部分成果，暴露没有遇到过的问题，二是加快项目周期。 5、验收阶段，如时间不充裕，严格按照需求确认的进行验收，当然要本着把项目做好的态度完成研发和验收，最后总结项目经验，包括人、业务、流程等等。 |
| 陈俊富  | 看了篇知识图谱论文 | 作者提出了一种基于神经网络的新颖方法来回答大规模知识库中的单关系问题，他利用RNN和CNN的优势互补来捕捉语义和文字先关信息。通过省略实体匹配模型让模型变得更加的简单化，这篇文章所提出的方法实现了有竞争力的结果。模型的精确度也都超过之前最佳结果一个百分点。 |
| 任星凯 | 总结MRC排行榜，看论文多跳阅读理解 | 总结了下常见的阅读理解[排行榜](https://github.com/renxingkai/MRC_Leaderboard)，看了下ACL19论文《Multi-hop RC through Question Decomposition and Rescoring》，作者将多跳阅读理解问题分解为几个单跳子问题，并根据几个推理类型基于span进行预测答案，相当于把一个复杂问题分解为多个简单问题，回答出简单问题，即原始问题也解决了，使用BERT+多段落选择进行主要模型设计，在HotpotQA上也达到了SOTA。
|刘洋|长序列多分类比赛|对于长序列问题，暂且还是用TextCNN，本周主要是对一些参数进行调优，如filter_num、filter_size、序列截取长度，然后在GlobalMaxPooling后还添加了GlobalAveragePooling。其中添加了全局平均池化后，最终loss有所降低。|
|Xin|爬虫|继续学习网络爬虫，在抓取一些公共信息网站当中，遇到很多问题，如文本清洗、BFS、DFS，在对得到的数据进行处理的环节花费了很多时间，有些问题仍未解决，如正则表达式，和字典转换问题|

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
