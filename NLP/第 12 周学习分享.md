时间：2019年6月10日 ~ 2019年6月16日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
海龙 | diverse beam search | 看到一篇16年的文章，讲的是如何改进beamsearch的，提升 seq2seq 模型decoding时候的多样性（diversity）。具体策略是将传统的beamsearch 改为 group beam search，然后组与组之间的概率差别人为的增大，使得 decoding 结果的 diversity 增强。优势在于，一般 seq2seq 模型，尤其是在对话中，容易出现通用回复，加了这个策略，即使生成句子的成句概率不是很高，但通顺度至少能够得到保证，diversity会明显提升。而且这个策略不参与训练过程，可以封装成tool，即插即用。（地址：https://arxiv.org/pdf/1610.02424.pdf）
任星凯|这周主要在用BERT造轮子| 使用BERT+BIDAF,BERT+QANET等BERT与传统阅读理解模型结合的方式来完成阅读理解任务，推荐一篇论文《 BERT Post-Training for Review Reading Comprehension and Aspect-based Sentiment Analysis》，主要提出了用用户的评论数据去回答用户提出的问题，这个点子也比较novel，降低了制作MRC数据集的难度，同时也更具有领域性、针对性，即文中提出的domain、task knowledge，使用BERT去进行阅读与回答、用户aspects情感分类等，虽然BERT的“后设计”并不复杂，但是提出了post-training这一方法，综合BERT的MLM和NSP进行训练与损失值表示DK，接下来进行DK与MRC的联合训练，这样既可以学习到领域相关知识，尽可能地忽略原始训练BERT时的wiki等知识，出于点子的新颖与实验的完备，还是一篇很好的论文。附上code链接：https://github.com/howardhsu/BERT-for-RRC-ABSA/
李昌群|Bert应用在RACE数据集| 学习了基于pytorch实现的Bert，主要关注了Bert微调在RACE数据集上，下周进一步研究，看能否尝试进行一些改进。 

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
