时间：2019年6月17日 ~ 2019年6月23日

| 学习人  | 学习任务    | 学习心得和参考资料                                |
| ---- | ------- | ---------------------------------------- |
| 段金强   | 学习预训练模型 | 预训练模型(pre-trained model)是为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从类似问题中训练过的模型入手。 预训练模型是深度学习架构，已经过训练以执行大量数据上的特定任务（例如，识别图片中的分类问题，Word2vec的语言模型，和最近大火的BERT）。 预训练模型是在训练结束时得到一组比较好的权重值，这些权值在我们类似的模型中也可以使用，减少了我们训练的时间，最后进行微调就可以验证我们自己的模型。我们可以在github上找到许多具有权重的库，但是获取预训练模型的最简单方法可能是直接来自您选择的深度学习库。 作者给出了很多预训练的模型：<https://www.jianshu.com/p/7e13a498bd63> |
| 李昌群 | 阅读Convolutional Spatial Attention | 在这篇论文中，主要关注多项选择阅读理解问题（RACE），提出了一种新的方法，称为卷积空间注意(CSA)模型。该模型能够充分提取文章、问题和候选项之间的相互信息，形成丰富的表征。此外，为了合并各种注意结果，使用卷积运算来动态总结不同区域大小内的注意值。 |
| Yang | word2vec | 学习了 word2vec 的两种方式，cbow 和 skip-gram，以及各自的两种优化方式，层次 softmax 和负例采样。|
| 海龙 | kgcvae | 看了kgcave的原论文(Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders)，并在微博对话数据上加以实现，发现结果主题信息的kgcvae的效果挺不错。|
| 王耿鑫 | 事件抽取 | 看了一些关于事件抽取的论文。根据抽取方法的不同，事件抽取可以分为基于模式匹配的事件抽取和基于机器学习的事件抽取。之前我尝试过用模板匹配的方法进行事件抽取，在抽取事件触发词和事件元素上效果不错，但是可迁移性较差。近几年用机器学习来进行事件抽取的效果提升很多，下一步考虑尝试下这些方法。 |
| 陈俊富 | 看知识图谱论文 | 本周看了一篇知识图谱论文综述及其在医疗领域的应用的论文，该文主要讲述了目前知识图谱在医疗领域普遍存在效率低、限制多、扩展性差等比较多的问题，首先分析了医疗数据的特点，对医疗数据进行了全面的剖析。然后又对知识图谱中知识表示、知识抽取、知识融合和知识推理这4个模块的关键技术和研究进展进行综述，并且对这些技术进行实验分析和比较。首先是知识表示，知识表示按照计算方式不同分为距离平移模型和语义匹配模型，然后是医学知识抽取，这个就是比较了解的，包括有实体抽取，关系抽取和属性抽取。主要的技术有支持向量机模型、人工神经网络、隐马尔可夫模型、条件随机场、BiLSTM-CRF模型等，医学知识融合主要是为了将不同来源的多元异构、语义多样、动态演化的医学知识在同一框架规范下进行异构数据的整合、消岐，加工、推理验证、更新等。医学知识融合的关键技术有实体对齐技术、实体链接技术和关系推演技术。最后，医学知识推理主要是为了丰富、扩展知识库；常用模型有人工神经网络模型、遗传算法和反向传播网络模型等。|
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
