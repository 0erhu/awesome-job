时间：2019年6月17日 ~ 2019年6月23日

| 学习人  | 学习任务    | 学习心得和参考资料                                |
| ---- | ------- | ---------------------------------------- |
| 段金强   | 学习预训练模型 | 预训练模型(pre-trained model)是为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从类似问题中训练过的模型入手。 预训练模型是深度学习架构，已经过训练以执行大量数据上的特定任务（例如，识别图片中的分类问题，Word2vec的语言模型，和最近大火的BERT）。 预训练模型是在训练结束时得到一组比较好的权重值，这些权值在我们类似的模型中也可以使用，减少了我们训练的时间，最后进行微调就可以验证我们自己的模型。我们可以在github上找到许多具有权重的库，但是获取预训练模型的最简单方法可能是直接来自您选择的深度学习库。 作者给出了很多预训练的模型：<https://www.jianshu.com/p/7e13a498bd63> |
| 李昌群 | 阅读Convolutional Spatial Attention | 在这篇论文中，主要关注多项选择阅读理解问题（RACE），提出了一种新的方法，称为卷积空间注意(CSA)模型。该模型能够充分提取文章、问题和候选项之间的相互信息，形成丰富的表征。此外，为了合并各种注意结果，使用卷积运算来动态总结不同区域大小内的注意值。 |

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
