时间：2019年6月17日 ~ 2019年6月23日

| 学习人  | 学习任务    | 学习心得和参考资料                                |
| ---- | ------- | ---------------------------------------- |
| 张三   | 学习预训练模型 | 预训练模型(pre-trained model)是为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从类似问题中训练过的模型入手。 预训练模型是深度学习架构，已经过训练以执行大量数据上的特定任务（例如，识别图片中的分类问题，Word2vec的语言模型，和最近大火的BERT）。 预训练模型是在训练结束时得到一组比较好的权重值，这些权值在我们类似的模型中也可以使用，减少了我们训练的时间，最后进行微调就可以验证我们自己的模型。我们可以在github上找到许多具有权重的库，但是获取预训练模型的最简单方法可能是直接来自您选择的深度学习库。 作者给出了很多预训练的模型：<https://www.jianshu.com/p/7e13a498bd63> |

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
