时间：2019年6月24日 ~ 2019年6月30日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
 李昌群 | 阅读理解模型论文Gated Attention Reader | 论文针对cloze-style问题提出，迁移到RACE数据集上。可以把其看成是AS reader模型的扩展，尽管模型简单，但是也取得了不错的成绩，也证明了乘法操作机制带来的效果显著。论文提出的Gated Attention用更细粒度的attention计算获得answer的定位，收获了一定的效果，并且使用Multi-Hop的结构，带着问题重读文章K次，增量式地重新得到tokens的表示，可以进一步帮助锁定答案。 

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
