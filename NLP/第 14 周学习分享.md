时间：2019年6月24日 ~ 2019年6月30日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
 李昌群 | 阅读理解模型论文Gated Attention Reader | 论文针对cloze-style问题提出，迁移到RACE数据集上。可以把其看成是AS reader模型的扩展，尽管模型简单，但是也取得了不错的成绩，也证明了乘法操作机制带来的效果显著。论文提出的Gated Attention用更细粒度的attention计算获得answer的定位，收获了一定的效果，并且使用Multi-Hop的结构，带着问题重读文章K次，增量式地重新得到tokens的表示，可以进一步帮助锁定答案。|
 |刘洋|关系抽取|本周学习了PCNN和split CNN，其中PCNN是对文本分割成三段：实体1左边的部分、实体1到实体2的部分，实体2右边的部分，然后在三段分别进行全局最大池化，将结果合并到一起。split CNN是把文本分成均等的三部分，然后每一部分分别进行卷积，k max pooling，然后再进行合并。尝试了这两种方法，但是效果一般。|
 | 王耿鑫 | 远程监督 | 本周学习了远程监督。对于关系抽取，目前常规的做法之一是将其视为命名实体识别和关系分类的组合。关系分类的做法是：输入一对实体词及其相关特征，预测关系类别。要构建这样的分类器，涉及到两个问题，①关系类别需要已知；②需要训练数据。这时候，如果有一个知识库，那么我们可以得到一些已知的类别。为了避免人工构建训练数据，远程监督被提出了，它基于知识库来构建训练数据。方法很简单，对于知识库中出现实体对，去语料库匹配句子，之后一起生成特征，将已知的实体关系作为所要预测的类别，这样就构造了训练数据。这里有一个很强的假设：如果我们训练语料中的句子所包含的实体对在知识库中有关系的体现，那么我们认为语料库中所有包含相同实体对的句子都表达此关系。所以，远程监督这种“偷懒”的方式其实会引入很多噪声，不过近些年对噪声的过滤也有不少研究。 |
|陈俊富|命名实体识别|本周主要学习了tensorflow，学习如何构建神经网络，以及各个优化器的作用；报名参加命名实体识别评测，主要识别医学实体，实体分为6类，包括手术、检查、检验等，下载代码调试。在运行代码的过程中，出现ResourceExhaustedError错误，目前正在查找具体Bug原因。学习概率论，最近几周考试，所以本周没看论文。|
|Yang|FastText、TextCNN|阅读微信推送文章 [推荐：常见NLP模型的代码实现（基于TensorFlow和PyTorch）](https://mp.weixin.qq.com/s/1QvOtO2-Me8bCivQ2Qk40Q)，主要看了 FastText 和 TextCNN 的代码和论文。|
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
