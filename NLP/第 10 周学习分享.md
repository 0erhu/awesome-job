时间：2019年5月27日 ~ 2019年6月2日

| 学习人  | 学习任务        | 学习心得和参考资料                                |
| ---- | ----------- | ---------------------------------------- |
| 段金强  | 学习WaveNet网络 | WaveNet可以用来做语音识别或语音生成。 WaveNet是2016年主要由Google旗下的Deepmind团队推出，提到借鉴了PixelCNN在图像上的应用，大致的思想就是利用图像中先前生成的像素点来进行新像素点的生成。图像是二维的，那么应用在音频信号中，则是一维的。基于这种理念，我们可以想到生成我们当前的音频信号也可以基于先前的音频。WaveNet设计思路，使用一个叠层的一维卷积（也称为因果卷积casual convolutional layers）来进行表示。 如果要提高我们的感受野，那么我们需要增加额外的层数，最终导致的结果是，我们需要花费巨额的计算量。 为了减少计算量和提高感受野，论文中使用了膨胀因果卷积（dilated casual convolutional layer）。 方法：每个卷积层都对前一层进行卷积，卷积核越大，层数越多，时域上的感知能力越强，感知范围越大。在生成过程中，每生成一个点，把该点放到输入层最后一个点继续迭代生成即可。 |
| 任星凯  | 学习Bert在阅读理解上的用法 | 使用的是pytorch版本的bert，把源码大致过了一遍，pytorch版本的代码看起来确实比TF版本更舒服点，可读性更高，这周实现了在Bert embedding层上concat其他文本特征(wiq、问题类型等)，但是效果都变差了，可能是自己打开方式不对；在Bert后面加了对答案的分类判别；只打开最后两层，冻结之前的层等思路 |

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
