## 本期内容

- 黄海广：统计学习方法代码开源
- QFR：算法策略学习
- 上邪：计算机视觉入门文章
- 波特：隐马尔科夫模型
- 活化石：维度灾难
- yang：FFM
- Hug蜗牛：论文阅读


### 黄海广：统计学习方法代码开源

李航老师的《统计学习方法》可以说是机器学习的入门宝典，我将这本书的算法用Python代码复现了，并做成在线阅读版本，可以利用碎片时间阅读。推荐收藏慢慢学。[经典复现：《统计学习方法》的代码实现](https://mp.weixin.qq.com/s/71w0IN3gAYWxrKVM_lcYrQ)


### QFR：算法策略学习

上周考试复习了算法中的各种策略。并且学习了BP算法模型，玻尔兹曼机，受限玻尔兹曼机中的公式推导，Gibbs采样的原理，信度网络，还有深度置信网络。了解清楚了wake-sleep算法的原理流程，CD-k的思想。理解并推导了线性支持向量机中的线性可分情况与线性不可分情况的公式（其中SVM里的KKT条件，对偶问题，对偶问题中利用Smo的求解，由对偶问题得到原问题的解），以及非线性支持向量机中高维映射的思想，并且对于带核的SVM，参数优化时应该注意的问题，网格搜索等。

### 上邪：计算机视觉入门文章

发现一篇[文章](https://zhuanlan.zhihu.com/p/31727402)非常赞，梳理了计算机视觉的四个基本任务（识别、定位、检测和分割），介绍了其中经典的网络和算法，非常适合入门。

![](https://mmbiz.qpic.cn/mmbiz_png/icmWrEONNM8VlS5oJOBu9cUt9XloO7LWedqXEXuQY3Vp7ebnotUFb1klXLaxqpYID1xtMk85F1GDTaiakQLNSL0A/0?wx_fmt=png)

花了几天时间看了目标检测中R-CNN家族算法。

R-CNN将提取候选框方法（Selective Search）和CNN提取图像特征方法结合起来，应用在目标检测任务上，取得了巨大的进步。R-CNN的过程是先利用Selective Search在原图上提取候选框，然后分别送到CNN中提取出各自的图像特征，并将这些特征送到SVM分类器中做识别，然后把那些识别为目标的图像特征送到边框回归器中校正边框位置。

R-CNN有一些明显的缺陷，比如训练繁琐，需要微调网络+训练SVM+训练边框回归器；每张原图约有2000张候选框，每个都要进行特征提取，导致大量的重复计算，耗时且占用大量的磁盘空间。针对这些问题，Fast R-CNN做了三点改进。一是只对原图做一次特征提取，然后将选择出来的候选区域映射到特征图上，直接从特征图上得到候选框的特征；二是利用ROI池化层（即单层SPP），将不同尺度的候选区域特征转化为固定的尺寸，便于和后面全连接层对接；三是利用多任务损失函数(multi-task loss)，将边框回归器（改为Huber损失）和分类器（改为softmax）放在一块训练。经过改进，Fast R-CNN把处理一张图像的时间从47s降到了0.32s（不包括提取候选框的时间）。

提速之后，大佬们愈发对Selective Search的龟速不满（提取一张图像的时间近2s），于是干脆把这一个环节干掉，在Faster R-CNN中将其换成RPN（Region Proposal NetWork）。RPN的结构很简单，只有两层卷积，利用一个分类器和一个边框回归器，直接从特征图上提取候选框，然后送到后面进一步细分。经过改进，Faster R-CNN把处理一张图像的时间从2s降到了0.2s（包括提取候选框的时间）。

### 波特：隐马尔科夫模型

学习了隐马尔可夫模型，隐马尔可夫模型由状态转移概率矩阵，观察概率矩阵以及初始状态概率向量这三部分确定。其中，状态转移概率矩阵与初始状态概率向量确定了隐藏的马尔可夫链，成不可观察的状态序列；观察概率矩阵确定了如何从状态生成观察序列。
       
隐马尔可夫模型有两个假设：
1. 隐藏的马尔可夫链在任意时刻t的状态只依赖与其前一时刻的状态。
2. 任意时刻的观察只依赖于该时刻的马尔可夫链的状态，与其它观测及状态无关。

隐马尔可夫有3个基本问题：
1. 概率计算问题；由模型及观察序列，求在该模型参数下观测序列出现的概率；
2. 学习问题；由观测序列学习模型参数；
3. 预测问题；给定观测序列求最可能状态序列

### 活化石：维度灾难

维度灾难：维度灾难用来描述当（数学）空间维度增加时，分析和组织高维空间（通常有成百上千维），因体积指数增加而遇到各种问题场景。

维度灾难导致的两个问题：
1. 计算问题：随着维数的提高计算的数据量会呈指数级增长，开高维数组时会瞬间耗光内存
2. 分类性能问题：当随着维度的上升，分类性能越好，超过临界值后，反而下降（直观理解，维度越多，样本在高维空间的分布越散，越不好找到分割面进行分割）

梯度消失和爆炸：链式法则会让参数梯度乘在一起，那些参数的特征值大于一就会梯度爆炸，小于1就会梯度消失。

### yang：FFM

FFM（Field-aware Factorization Machines）是 FM （Factorization Machines）的升级版，通过引入 field 概念，把相同性质的特征归类到一个 field 中，在 FFM 的每一个特征都会针对每一个 field 学习一个 k 维的隐向量，所以，隐向量不仅跟特征有关，也跟 filed 有关，所以该模型的时间复杂度是平方级别的，不能像 FM 那样优化到线性时间，特殊地，FM 可以看成是 FFM 的特例，所有特征都在一个 field 中。在二阶项添加新特征的时候，直接使用 hash 来创建，避免使用循环来创建。而且 FFM 可以通过数据并行的方式来加速。对于 FFM 的数据，最好都要是离散类型的特征（如果是连续型，可以通过 bin 的方式做处理），此外，FM 和 FFM 对于大规模系数的数据都能有很好的效果（优于ploy-2），而且稀疏数据使用 libsvm 的格式存储，也能有助于加速。对于不稀疏的数据，FFM 并不能带来很好的收益。

相关资料

1. [Field-aware Factorization Machines for CTR Prediction](https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf)
2. [Field-aware Factorization Machines YuChin Juan, Yong Zhuang, and Wei-Sheng Chin NTU CSIE MLGroup](https://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf)
3. [CTR预估算法之FM, FFM, DeepFM及实践](https://blog.csdn.net/john_xyz/article/details/78933253)
4. [推荐系统FM & FFM算法解读与实践](https://blog.csdn.net/baymax_007/article/details/83931698)

### Hug蜗牛：论文阅读

本周主要阅读了论文，论文主要讲解的是利用一个姿态词典，然后再语义层面对动作进行识别，本篇论文的作者主要是利用机器翻译的对齐模型，将姿态特征和视觉特征对齐，然后求出这两者之间的相关向量a,最后利用中间关系a,对动作进行识别，该方法在MSRC-12数据集和WorkoutSu-10数据集上都得到了很好地效果，[论文地址](https://arxiv.org/abs/1604.00147)




## 加入我们

公众号内回复「**自学**」，即可加入ML自学者俱乐部社群。可以投稿每周学习心得或者优质学习资料，助力团体共同学习进步。

[上期精彩内容](https://mp.weixin.qq.com/s/RslxAe979jZkJ0Q_msyHnw)


