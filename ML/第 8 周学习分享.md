时间：2019年5月13日 ~ 2019年5月19日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
李小川 | 泰坦尼克号幸存者预测 | 今天首次尝试kaggle的比赛项目，通过最简单的一个泰坦尼克预测，初步熟悉做kaggle的步骤，感觉最主要的还是前期的数据清洗，因为算法和训练模型有现成的包可以使用，比如，姓名怎么做特征值？生存与否好像和姓名无关，但是若是发现姓名中的称呼，如master，Miss等等就可以将其提取出来，单独做一个特征值。其次还有模型的选择，我用逻辑回归和SVM分别做了预测并提交，排名结果并不太一样。但是最终感觉最困难的还是如何利用Python做数据分析。
陈亮 | 巩固pandas + 听netflix分享 | 这周和朋友吃饭，听他说了面netflix的事，说是可以给到40万美刀(羡慕的我直流口水)，言归正传所以我去找了些netflix做machine learning相关的分享看了看。Netflix用的是aws的cloud，他们有自己的一套ML框架可惜没有开源。他们在做内容推荐时候经常使用的工具和方法是:Regression models(logistic, linear, Elastic nets), GBDT/RF,SVD & other MF models, Factorization Machines, Clustering(from K-means to HDP), Deep ANN, LDA, Association Rules.了解到Netflix之前举办的比赛悬赏1百万奖金改进推荐系统，但是最后的得第一的model他们并没有使用，原因是这套model太注重准确率而没有考虑到deployment以及实用性。总结一句话就是: Data science is not just about accuracy it's also about latency and ease of maintenance and ease of production。继续在datacamp练习pandas, 本周主要是围绕着dataframe的相关操作进行了练习，最后进行了一个小的数据分析练习叫Sunlight in Austin，主要是利用pandas将数据从csv读取出来，最后生成chart。
刘嘉艺|tensoflow实现无条件gan|本周主要学习了gan结构，主要是网络结构和loss构造，思想确实很巧妙。搭建gan网络过程中也是遇到不小的问题，主要是一些细节问题比如生成网络和判别网络的输出层激活函数选择，loss的组成，gnet和dnet要分开训练（训练g时要固化d，训练d时要固化g）。
成文浩 | A Survey on Few-Shot Learning | 论文将现有的小样本学习的模型分为四类，分别是1.多任务学习（multitask learning ）  2.嵌入学习（embedding learning） 3.额外信息的学习（learning with external memory） 4.生成模型（generative modeling）
袁林 |卷积神经网络 |这周学习了卷积神经网络，主要学习什么是卷积神经网络，了解了其基本的概念和操作，主要还是用于图片处理，padding用于使图片经过处理后不会变的较小，一般可以初始化为0，实现时可以适当的调节其运动步长，池化层一般用Max pooling选择的是其固定区域内最大的值，Average pooling 则是计算选中部分的平均值，这周学的是理论知识，下周开始实践。
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

