时间：2019年9月9日 ~ 2019年9月15日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
陈亮 | LDA | 1. 本周主要是学习了一下LDA. 主要通过分析论文找到机器学习最火话题 2. LDA采用的是贝叶斯学派的思想， 认为待估计的参数（主题分布和词分布） 不再是一个固定的常数， 而是服从一定分布的随机变量 3.（面试高频问题）关于如何确定LDA中的topic个数(预先设定好的超参数)，我觉得大家一般都认可的是当各个topic之间相似度最小的时候，也就是冗余最小的时候我们就相当于找到了合适的topic个数。Perplexity (困惑度), topic coherence可以作为衡量模型的指标，但是效果不一定很准确，如果能用肉眼检查最好不过了 4. 随着topic增多perplexity会随之下降，但当topic过多的时候我们要注意可能是over-fitting了。另外需要注意的是，我们要考虑到实际应用中我们并不能接受很大的topic数目 5. 除了LDA这种需要自己确定topic数量的模型，还有一些被称为非参数主题模型的叫non-parametric topic 非参数主题模型，比如HDP, hLDA, ICD等这类模型无需实现认为指定参数。需要注意的是非参数主题模型会让计算变得更加复杂，需要大量时间，所以在实际应用中我们更多的是使用前者 6. 在推荐系统中我们可以使用LDA，我们可以将用户当做文档来对待，提取主题信息当做关键词匹配。
具信 | 看数学方面的书 | 不着急进度，趣味阅读，看了两本书，一本《心理统计学》，这本书没什么意思，三分之一放弃。另一本《古今数学思想》，梳理数学发展的脉络，启发思维，富有趣味，看了三章，到欧几里得的《原本》，开始引人入胜，也越来越复杂，不太适合当闲书看了(lll￢ω￢)
333|基础统计复习，继续凸优化学习|applied lineer statistical model 中的 linear 讲解感觉和以前所学到的完全不一样，很有意思的书。 convex optimization 是以前没有学过的，感觉很难，慢慢来吧。

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
