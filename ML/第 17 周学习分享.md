时间：2019年7月15日 ~ 2019年7月21日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
杨建民 | 统计学习方法-逻辑斯谛回归与最大熵模型 | 逻辑斯谛回归是统计学习中的经典分类方法．最大熵是概率模型学习的一个准则，将其推广到分类问题得到最大熵模型，逻辑斯谛回归模型与最大熵模型都属于对数线性模型。这章的公式奇多，看得云里雾里。不知大家怎么学习的？
具信 | 《普林斯顿微积分读本》第22-26章的学习 | 本周学习的是数列和级数，主要学习级数的求解、收敛性的判别法。重点在于泰勒多项式/级数（麦克劳林级数）和幂级数，用级数求解函数的估算问题。[22-26章笔记](https://www.jianshu.com/p/c1eb2292c652)
陈亮 | DS 面经 + 常用nlp技巧 | 这周主要看了一些data scientist的面经，发现一个很有用的资料a collection of Data Science take-home challenges感兴趣的小伙伴可以买来看看（尽量尊重别人的劳动成果）https://datamasked.com/ 。另外学习了一些nlp相关的技巧 1. tokenise on punctuation这样就避免了连字符和下划线等。2.unigram, bi-gram可以获取information involving multiple token，代码例子:vector = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC, ngram_range=(1, 2))。3.interaction term 代码例子：interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)。4.当我们在添加新feature时候如果使得array size增长很大的话，我们可以用hashing这样就限定了output，当我们有非常多的text data时候尤其要考虑这个技巧
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
