时间：2019年7月1日 ~ 2019年7月7日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
具信 | 《普林斯顿微积分读本》15-20章 | 这周学习的是积分的定理、常用公式和求不同类型积分的方法： [15-20章笔记](https://www.jianshu.com/p/55507165b817)
陈亮 | sklearn | 这周主要是学习使用scikit-learn。使用sklearn进行一些练习，发现sklearn真的很好用，train_test_split 从样本中划分出训练和验证数据，cross validation(cross_val_score) 对数据进行交叉验证准确率,另外学习了ridge regression和 lasso regression。Lasso 和 ridge 都是基于线性回归模型防止过拟合的工具,工业上常用lasso。通过混淆矩阵Confusion matrix来衡量分类器的准确率。以及ROC curve用来比较两个分类模型好坏的可视化工具。
杨建民 | 朴素贝叶斯法 | 这周主要学习了朴素贝叶斯法，统计学习方法书里的文章一般都非常概要，要深入学习还需要其他资料进行补充学习，一般可以从其他博客进行了解。朴素贝叶斯法是典型的生成学习法，由训练数据学习联合概率分布，然后求后验概率分布。朴素贝叶斯法的基本假设是条件独立性，这个要求比较高的。朴素贝叶斯法利用贝叶斯定理与学习到的联合概率模型进行分类预测，后验概率最大等价于0-1损失函数时的期望风险最小化。
333|继续小白的机器学习之路|开始跟着书和教程做小项目了，不单单是看原理了，发现有趣的地方，比如确实可以自己上手预测，用户好坏，价格什么的，但是也发现了几个不足和问题 1.整个过程的思路还是跟着教程和书，离开了就没什么自己的思考了。2.使用不同的模型来训练一些数据，得出的结果相差很小（可能是我用的数据太简单了？或者是模型没有用好？）用LR模型和XGBOOST模型来处理LendClub的信用卡用户数据，以此来判断用户好坏，想试试这两个，分别做对比，结果AOC,ROC都是一样的，没啥变化，这个问题可能得等我继续深入学习了才能解决吧。3.想到一个问题，机器学习在实际工作中的导向是什么呢，是公司提出一个实际需求，然后大家来搞出一个准确度尽可能高的模型嘛，今天看到说在数据量很大的时候，很多模型的准确度相差很小，那么拼死拼活提升的百分之零点几意义何在呢，会有一个具体的表现吗。这些问题留着下星期继续改进和思考！
Yang | CNN | 了解 CNN 的细节，重点是 conv 和 pooling 层的求导。

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下
