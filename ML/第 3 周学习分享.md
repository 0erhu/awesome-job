时间：2019年4月8日 ~ 2019年4月14日

学习人|学习任务|学习心得|参考资料
------ | ------ | ------ | -----
李小川  | 正则化逻辑回归|对线性可分的模型进行了温故后又复习了一遍线性不可分的算法，才算缕清楚了前后递进的关系，以及中间几个步骤的意义，如特征映射，正则化。同时对numpy的几个函数做了详细了解如numpy.exp(),numpy.log()。| 具体的总结在博客https://blog.csdn.net/lixc316/article/details/89070140 
刘天宇  | 金融数据分析　| 通过这周的学习，基本了解如何使用机器学习来做金融数据分析，学会使用LSTM神经网络预测股票价格，学习了如何通过机器学习预测股票涨跌。
袁林     | 机器学习前三周总结| 这周总结了下前三周常用的几个函数用法，zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。numpy.linspace（）函数，np.meshgrid函数接受两个一维数组，并根据两个数组的所有（a,b）对生成一个二维矩阵。reshape()方法来更改数组的形状，还有一些科学算法的传参（内置算法还不太明白，需要弄明白）。
陆开胜 | 聚类算法 | 这周大部分时间在翻译小论文，在学习yolo算法的过程了解到其中几种anchor prior的尺寸是通过k-means算法聚类得到的，所以对聚类算法进行学习了一遍。| 一些总结https://blog.csdn.net/shaile7593/article/details/89300177
王鸿博 | keras框架学习 | 因为复现论文需要，这周学习了一下keras框架，keras是一个基于python的深度学习库，以tensorflow或者theano作为backend，封装了许多常用的函数，非常简单就能建立起一个神经网络。
成文浩 |Few-Shot Learning with Graph Neural Networks| ## 输入

$$
\mathcal{T}=\left\{\left\{\left(x_{1}, l_{1}\right), \ldots\left(x_{s}, l_{s}\right)\right\},\left\{\tilde{x}_{1}, \ldots, \tilde{x}_{r}\right\},\left\{\overline{x}_{1}, \ldots, \overline{x}_{t}\right\} ; l_{i} \in\{1, K\}, x_{i}, \tilde{x}_{j}, \overline{x}_{j} \sim \mathcal{P}_{l}\left(\mathbb{R}^{N}\right)\right\}
$$

其中s为有标签的样本数量，r为无标签的样本数量，t为待分类的样本数量，其中所有x独立同分布。

## 第一步

将输入 $\mathcal{T} $ 转换为全连接图$G_{\mathcal{T}}=(V, E)$ ，其中$v_{a} \in V$  代表图片$x$ (包括有标签和无标签的)。

## 初始化

图$G$ 的初始值通过下式得到
$$
\mathbf{x}_{i}^{(0)}=\left(\phi\left(x_{i}\right), h\left(l_{i}\right)\right)
$$
其中$\phi\left(x_{i}\right)$ 是一个CNN，$h(l_{i})$ 是独热码。 |
