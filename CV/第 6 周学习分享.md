时间：2019年4月29日 ~ 2019年5月5日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
安军刚 | Poisson Image Editing  | 图像无缝接合技术(泊松分布图像编辑)，由Microsoft Research UK的Patrick Perez，Michel Gangnet, and Andrew Blake在论文“Poisson Image Editing”中首次提出，这个是布朗大学对该项技术研究的主页:http://cs.brown.edu/courses/csci1950-g/ .这个技术主要是解决光学图像在目标检测与全景分割中亚像素本身的联通域问题造成导数图像问题。里面结果和实验在该博客中述:https://blog.csdn.net/majinlei121/article/details/47258389该技术学习只是我做文字识别时候遇到一个复杂问题的一部分。
安静  | YOLO论文学习 | 从YOLOv1到YOLOv3，层数越来越多，识别效果越来越好，在保持识别速度的前提下，作者对网络进行了全方位的优化，改进了很多细节的东西，Better、Faster、Stronger，总结如下；
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 安军刚的学习心得
计算机视觉由于采用贝叶斯分类器方案所以存在这种贝叶斯本身分类概率的上下限问题，基于泛函分析的约束和特定环境的大规模卷积神经需要设计一个适应工程的损失函数解决交叉信息熵传递的方法解决因此我们要看到贝叶斯方法的局限性和重构特定场景的卷积神经网络的理论依据
  在目标检测上最近很大anchorfree，但是个人理解这个是暂时性的技术替代问题本质目前个人理解只有NVIDIA的SSN解决，针对与ROI兴趣区域有显著性特征可以用相对特殊的方法处理获得，但是在深度学习中从早期的HOG、DPM、slid wndows、anchor、keypoint的思想出现了centerNet和cornernet其实和anchor的gridcell本质上一样。只是在上采用使用了卷积替代了双线性插值方法让模型具备学习，目前我对模型进行各种测试发现RFBNet相对效果最好，其他的论文我复现结果相对而已效果和yolov3在工程水平一样，但是cascadeRCNN这个模型精度确实很高。 从核心看只是从一起的ROI pooling过程先画框再识别框中的内容到先识别分类再通过预设的anchor聚类计算距离使其计算大幅度减少。那么说明这个阶段只是解决工程问题学术本质定位的像素联通域在卷积过程时域和空间域是否真实具备完整的信息这个需要考证。
  在以上基础上我读RRPN这个论文Radar Region Proposal Network for Object Detection in Autonomous Vehicles中利用雷达图像映射方法实现高精度的召回率说明一种新的点映射方法可以提高定位，其实这个在分割中很常见例如反卷积和沙漏卷积，借助霍夫曼概率投票一个泊松分布来实现应该可以得到更好结果。

### 安静的总结
#### YOLOv1
- 首先将输入划分成S*S的网格grid cell。
- 然后对每一个网格进行操作，每个grid cell 预测B个bounding Box及其 confidence scores=P(object)*IOU(预测框与真实框)，同时预测每个大格子的类概率。 
- 最后设置阈值，通过NMS进行重复检测的去重。
#### YOLOv2
YOLOv2在YOLOv1在精准度以及速度这两个方面进行改进
- 精度方面：
	* Batch Norm:使用 Batch Normalization 对网络进行优化，让网络提高了收敛性，降低过拟合，同时还起到了正则化（regularization）的效果。
	* High Resolution Classifier:训练特征提取器(CNN)时，将预训练分为两步，先输入224大小的图片，在输入448大小的图片微调 10 个 epochs，这样在detection的时候网络可以很好的过渡了。
	* Convolutional with Anchor Box:预测 Anchor Box 偏移值与置信度，而不是直接预测坐标值,使神经网络学习起来更容易，，所以移除了产生坐标的全连接层替换为卷积来预测预测 Bounding Boxes。去掉了网络中一个池化层，让卷积层的输出能有更高的分辨率。
	* Dimension Clusters(先验框):在训练集的 Bounding Boxes 上跑一下 k-means聚类，使预测框与ground truth 的IOU更好。
	* Direct location prediction(控制bounding box的偏移量 ):使模型训练更稳定。
	* Passthrough:YOLO 加上了一个 Passthrough Layer 来取得之前的某个 26*26 分辨率的层的特征。它能够把高分辨率特征与低分辨率特征联系在一起(相邻的特征堆积在不同的 Channel 之中)，预测更小物体。
	* Multi-Scale Training:YOLOv2 能健壮地运行于不同尺寸的图片之上,YOLOv2 每迭代几次都会改变网络参数。每 10 个 Batch，网络会随机地选择一个新的图片尺寸。
- 速度方面：提出一个更精简的网络 (Darknet-19)，替换了原来的vgg网络，减少参数提升速度。
