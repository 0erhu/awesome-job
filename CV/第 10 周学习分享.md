时间：2019年5月27日 ~ 2019年6月2日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
唐洋 | tf serving & android tflite & tfjs 学习 | 心得如下
李钊 | tersorflow框架学习|这周还在继续学tensorflow网络框架，下周大概可以把学完，到时候单独整理一个博客。老实说tensorflow感觉是一种新的数据工具，虽然感觉学起来很简单，但是里面有很多比较繁杂的部分需要自己去做一下理解，争取以后不去复制别人的代码，加油！
安静 |ICDAR2013 文字检测衡量方法|心得如下
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 唐洋的学习心得
## tf serving & android tflite & tfjs

使用[tf serving]部署模型到线上，使用python flask作为中间件，将训练好的模型迁移到[android]中和[web]中。

##### [tfjs版QuickDraw](https://github.com/Mic-JasonTang/QuickDraw)
1. 你通过这个任务学到了什么？

	#### TensorFlow Serving

	Q: 为什么会有Tensorflow Serving？
	A: 一般来说训练时所做的操作和真正部署预测时所做的操作是不一样的，`tf serving`可以将开发环境中的模型快速部署到生产环境中，在保持其基本功能状态不变的情况下还能高效执行提供服务。

	Q: TensorFlow Serving是什么？
	A: `TensorFlow Serving`是一种灵活的高性能服务系统，专为生产环境而设计，适用于机器学习模型。使用 `TensorFlow Serving` 可以轻松部署新算法和实验，同时保持相同的服务器架构和 API。

	Q: 如何使用TensorFlow Serving？
	A: 将训练的模型用`tf.saved_model()`保存下来，再使用`tensorflow_model_server`工具将模型部署为API接口的形式.
	`tensorflow_model_server --model_base_path=./saved_model --rest_api_port=9000 --model_name=QuickDrawClassifier`
	`TensorFlow Serving` 除了指定开放端口之外还需要使用 8500 端口作为 gRPC 服务端口，在实际部署时请保证该端口未被占用。

	Q: 如何调用通过tf serving部署好的api？
	A: 对 `TensorFlow Serving` 进行 `http post` 请求，请求 url 为 `http://localhost:9000/v1/models/QuickDrawClassifier:predict`, url 当中的 `QuickDrawClassifier` 即为上一步开启 TensorFlow Serving 时自定的名称。
	```
		url = 'http://localhost:9000/v1/models/QuickDrawClassifier:predict'

		payload = {
		    "instances": image.tolist()  # image要处理成在本地预测时一样的维度
		}

		r = requests.post(url, json=payload)
		pred = json.loads(r.content.decode('utf-8'))
		labels = getLabels()
		print(labels[np.argmax(pred['predictions'][0])])
	```

	Q: 如何将上面的API不具备预处理数据的功能，如何完善？
	A: 使用`Python Flask`完成数据预处理并暴露API接口，之后直接通过HTTP 的`POST`请求将图片数据转为字符串作为参数传入即可。
	```
		# 调用数据格式
		Http method: POST
		Input type: FormData
		Input data: {
		    'Data': String (Flattened image data (shape=[256*256*1]) to string, include "[" and "]" tags),
		    'Width': 256,
		    'Height': 256,
		    'Dim': 1
		}
	```

	<hr>
	
	#### TensorFlow Lite
	
	Q: 如何将训练好的模型放入`Android`中离线预测？
	A: TF在Android中支持PB文件格式的模型和TFLite文件格式的模型（推荐后者,使用`tf.contrib.lite.TocoConverter.from_frozen_graph`将pb转为tflite）。实验中是将PB文件转换为tflite文件格式。

	- 界面搭建好之后，首先通过字节流的方式将模型文件和标签文件[源码在这](https://github.com/theangels/TensorFlowLite/blob/master/app/src/main/java/org/blackwalnutlabs/angel/tensorflowlite/model/TensorFlowLiteDetector.java)读入，然后通过构造`org.tensorflow.lite.Interpreter`执行类的实例tfLite，将模型字节流以构造方法参数传入，再通过执行`tfLite.run(imgData, labelProbArray)`来预测。

	<hr>
	
	#### TensorFlow JS

	Q: 如何将训练好的模型放入`web`浏览器中执行？
	A: 将训练好的模型保存为相应格式，这里有两个方案：

	- 一种是以 Keras 的形式将模型导出然后使用 `tensorflowjs` 命令工具`tensorflowjs-conventer`做转换，另一种是使用 `tensorflowjs` 的 `Python API` 直接导出 `tfjs` 格式的模型。
	- 方案1: `model.save('model.h5')` 和 `tensorflowjs_converter --input_format keras model.h5 web_model`
	- 方案2: `import tensorflowjs as tfjs` 和 `tfjs.converters.save_keras_model(model, 'web_model')`
	- 保存的结果: 在`web_model`文件夹中存在`group1-shardof1` `model.json`两个文件.

	Q: 如何搭建web界面并执行？
	A: 首先搭建`web server` [这里下载源码](https://github.com/theangels/Express-Bone),然后执行`npm install`, 安装完毕依赖后执行`node app.js`启动服务在`http://127.0.0.1:3000 `.
	- 接下来，将 `class_names_min.txt` 文件和 ` model.json`、`group1-shard1of1` 文件，将这 3 个文件拷贝到`Express-Bone/public/model/`里。
	- 编辑 Express-Bone/templates/views/views 目录下的 index.pug 文件，添加 TensorFlow.js 和准备新创建的 action.js 依赖。
	```
		block javascript
		    script(src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js")
		    script(src='/js/action.js')
	```

	- 在`public/js`里添加`action.js`文件，并添加如下代码:
	```
		async function start() {
		    labels = $.ajax({
		        url: "model/class_names_min.txt",
		        async: false
		    }).responseText.split('\n');

		    model = await tf.loadLayersModel('model/model.json')
		    // const pred = model.predict(tf.zeros([1, 28, 28, 1]))
		    // console.log(pred.dataSync())
		}
		start()
	```

	- 编写数据预处理函数,使用tf.tidy代码块，该方法会自动清除代码块中所创建的中间`Tensor`，但会保留最终的返回值。	

	```
		function preprocess(imgData) {
		    return tf.tidy(() => {
		    	// 用 tf.browser.fromPixels 函数将 ImageData 转化为 Tensor，函数需要传入两个参数，一个是 ImageData，另一个是图像的通道数。
		        let tensor = tf.browser.fromPixels(imgData, numChannels = 1)
		        // 统一成 Tensor 之后，就可以对其进行正常操作，先把分辨率 resize 成 28*28，然后根据 Canvas 的图像值特点和模型的输入规则处理图像。
		        const resized = tf.image.resizeBilinear(tensor, [28, 28]).toFloat()
				const normalized = tf.fill([28, 28, 1], 255).sub(resized).div(tf.scalar(255))
				const batched = normalized.expandDims(0)
				return batched
		    })
		}


		canvas.mouseup(function () {
		    // 前面程序保持不变

		    // 预测代码
		    const imgData = cxt.getImageData(0, 0, 480, 480);
		    const pred = model.predict(preprocess(imgData)).dataSync()

		    var display = '您画的可能是: '

		    for(var i = 0; i < pred.length; i++){
		        if(pred[i] > 0.5){
		            display += labels[i] + ', '
		        }
		    }

		    if(display == '您画的可能是: '){
		        display = '我也猜不出您画的是什么'
		    }

		    $('#result').html(display);
		});
	```

2. 总结
	将模型部署成API、部署到手机、部署到web中。
	主要的步骤：
	- 训练模型: 准备数据集、数据预处理（归一化等）、模型搭建、模型训练
	- 保存模型: 根据迁移环境不同，保存为不同格式，API的格式为saved_model,使用`tf.saved_model.simple_save`来保存,`Android`的格式为`tflite`，使用`tf.contrib.lite.TocoConverter.from_frozen_graph`将`pb`转为`tflite`，`web`的格式为`tfjs`格式，使用`tfjs.converters.save_keras_model`来完成.
	- 加载模型: 根据迁移环境不同，加载方式不同，`API`的加载方式为`tensorflow_model_server`暴露API接口, `Android`通过字节流的方式读入模型和标签，`web`首先要引入tfjs依赖，然后使用`tf.loadLayersModel`来加载模型.
## 安静的心得总结

首先说明，文本检测既不是信息检索也不是目标检测。
evaluation方法有四个level：

1.  pixel feature discriminace
2.  pixel classification
3.  detection at rectangle
4.  target oriented

常用水平矩形检测和目标倾向性的方法。
一般的evaluation方法（object detection和text detection） 都有recall和precision的计算。得到这两个值后，object detection的evaluation会计算mAP， 而text detection的evaluation则计算F-mean. 
不同的方法的不同之处主要在于如何计算recall与precision，也就是怎么计算两个bbox是否match。
判断两个bbox是否match存在三种方式：
	* 一对一的match
	* 一对多的match，ground truth 粒度大于detection 粒度时出现的情况。
	* 多对一的match，detection的粒度大于ground truth的粒度。
	* 多对多的match 

不同的evaluation方法的不同的根源就在于对这三种match的处理方式不同。
而今天所说的 ICDAR2013，考虑了三种match方式：Deval
 1. 计算recall matrix与precision matrix
recall 与precision两个矩阵分别用σ与τ表示，它们都是|G|×|D|的矩阵，每一行代表一个Gi, 每一列代表一个Dj: 
                          -  σij=R(Gi,Dj)
                          - τij=P(Gi,Dj)
这两个矩阵合在一起也称为overlap matrices. i,j位置上的元素值不为0就代表Gi,Dj 之间有重合。
 2. 利用σ,τ表示三种match
tr,tp∈[0,1分别为σ,τ的阈值。算法能表示除了many-to-many以外的三种match方式：

	* one-to-one: 一个Gi只与一个Dj匹配 
	-- Gi的大部分范围只被Dj检测出来：σ的第i行只有σij≥tr
	-- 只有Dj检测Gi的precision符合要求: τ的第j列只有τij≥tp
	* one-to-many（splits）: Gi被D的一个元素数量大于1的子集Do检测出来： 
	-- Do中的每个元素都能一定准确度检测出Gi的一部分：τij≥tp,∀j∈Do
	-- Gi的大部分范围被So检测出来： ∑j∈Soσij≥tr
	* many-to-one(merges) : G一个元素个数大于1的子集Go被一个检测结果Dj检测出来 
	-- Go中的每个元素都有一定比例的面积被检测出来：σij≥tr,∀i∈Go
	-- Dj以一定准确度检测出Go：∑i∈Goτij≥tp
	
由此定义bbox的两个匹配函数MatchG，MatchD
