时间：2019年3月25日 ~ 2019年3月31日

学习人|学习任务|学习心得|参考资料
------ | ------ | ------ | -----
朱俊|deep_sort（写目标追踪有关deep_sort的博客）	| 这周的主要任务是复现并熟悉deep sort论文，下面简单回顾一下这周的工作：跑通了deep sort的代码，对detection结果的数据进行处理，并将检测结果送入deep sort实现目标追踪，调研deep sort评价算法并下载代码进行指标复现。记录复现过程，一些简单的思路。https://www.cnblogs.com/wemo/p/10600454.html，调研多目标跟踪MOT评价指标 https://www.cnblogs.com/wemo/p/10628836.html，其他工作就是在写一些数据处理的脚本和在原代码上进行数据批量操作，对原代码进行操作，这部分花了很多时间。今天下午听了一个会议，其中西安交大的孟老师的分享给我很大触动，看到了一个科研人的热忱和学识的渊博。
李钊 |五种机器学习算法python复现 |之前是搞嵌入式的，后来搞图像，最近刚刚把机器学习的十二种算法给学习完毕，打算把算法在matlab上复现一遍和python上复现一遍。这周首先复现五种算法，matlab上很顺利的复现周一就进行，python上复现出现一些问题，经过长时间的调试，发现居然是numpy和pandas的数据类型的问题。写博客时间有点久，而且这些算法比较老旧，讲解的人比较多，写博客有点浪费时间我把自己稍微加的拓展说一下吧。1.线性回归算法：写这个算法的时候，第一次使用python环境，由于numpy和pandas的数据结构不同，在矩阵相乘的时候，出现矩阵和数组成的情况，调试很久才发现问题。虽然，矩阵和数组相乘有些问题，但是在小的学习率和大的迭代次数时依旧可以有不错的效果，单步调试的发现是数组X矩阵时将矩阵每个元素乘以数组，还好有个加和。拓展了两个惩罚项，变成弹性网络回归。2.逻辑回归:在这个算法上，主要做了正常迭代和用优化器的对比，发现正常迭代约十万次才能和优化器结果相同，另外学习率稍微大一点都会引起发散。3.最近邻聚类：这个算法主要拓展是可视化的拓展，把边界画了出来。4.决策树：决策树算法相对简单，主要是提高了python的编程技巧。5.支持向量机：在支持向量机算法上，我是用python的高级库完成的，编程和算法上并没有大的收获，主要是调参时候发现可能出现局部最优的情况，基于这种情况了解了一下退货算法。这就是一周的工作，下周继续努力。 Ada	图像分类	本周工作比较忙，直接拿了mobilenetV2的网络进行在一个简单的私有数据集上予以训练。准确率和速度都不错。对训练过程中loss的写法，分类输出，以及数据的读入，有了实践认知。主要的阅读材料是：https://zhuanlan.zhihu.com/p/33075914。mobielnetV2的原论文
568	|人脸检测、图像分类网络研究	|本周学习了经典人脸检测和关键点定位算法mtcnn，该算法有三个神经网络结构pnet、rnet、onet，依次加深复杂，其中pnet是全卷积神经网络，方便对输入的各种像素大小的图像进行处理，并且首先判断人脸的是否后依次经过rnet和pnet进一步排除较差的人脸候选框来得到最优的人脸候选框，前两种net之后都要经过NMS的过程排除重叠的候选框中非最优的，pnet、rnet的返回值包括是否人脸和候选框的位置属性，onet的返回值包括上述两种外加5个关键点的x、y坐标，在训练过程中注意要把wider face中的数据裁切为边长12的方形后再放入pnet，为了加强训练效果，通常取70%的难例求梯度而简单例不进行误差的反向传播，在检测过程中，还需要把测试图片按一定的比例（常见根号2）进行一系列缩放，利用图像金字塔的性质来缩短运行时间。还学习了senet，通过学习对特征图层加成的权重来使得机器自己学习选择重要的特征图而稍忽略不重要的特征图，具体方法是对处理后的特征图另取一份全局感受野，并将通道数降低16倍后进行卷积再恢复，最后经过sigmoid进行权重分配，最后分别加回原特征图，计算量增长不大，适合嵌入到各种现有网络中，实测过程中因为gpu硬件对分组卷积的优化不好，使得其实际出现和resnext同样的问题即gpu实际计算时长远长于理论
安静 |	文字检测	Fast R-CNN未完待续| 这周还是让 Fast R-CNN 再飞一会 ，过去的这一周在训练EAST模型，ICDAR2015跑了10万次，并没有进行测试，loss值0.2左右。准备在MTW2018上跑，训练集坐标数据标的顺序与2015不同得改改。去学c++，awsl
赵鹏云|	目标检测yolo3	|本周学习了目标检测算法YOLOv3.YOLO算法的基本思想是：首先通过特征提取网络对输入图像提取特征，得到一定size的featuremap，比如13*13，然后将输入图像分成13*13个grid cell，接着如果ground truth中某个object的中心坐标落在哪个grid cell中，那么就由该grid cell来预测该object，因为每个grid cell都会预测固定数量的bounding box（YOLO v1中是2个，YOLO v2中是5个，YOLO v3中是3个，这几个boundingbox的初始size是不一样的），那么这几个bounding box中最终是由哪一个来预测该object？答案是：这几个bounding box中只有和ground truth的IOU最大的bounding box才是用来预测该object的。可以看出预测得到的输出feature map有两个维度是提取到的特征的维度，比如13*13，还有一个维度（深度）是B*（5+C），注：YOLO v1中是（B*5+C），其中B表示每个grid cell预测的bounding box的数量，比如YOLO v1中是2个，YOLO v2中是5个，YOLO v3中是3个，C表示bounding box的类别数（没有背景类，所以对于VOC数据集是20），5表示4个坐标信息和一个置信度（objectness score）。从v1到v3，速度和精度不断提升。Bounding Box Prediction：bounding box的坐标预测方式还是延续了YOLO v2的做法，简单讲就是下面这个截图的公式，tx、ty、tw、th就是模型的预测输出。cx和cy表示grid cell的坐标，比如某层的feature map大小是13*13，那么grid cell就有13*13个，第0行第1列的grid cell的坐标cx就是1，cy就是0。pw和ph表示预测前bounding box的size。bx、by。bw和bh就是预测得到的bounding box的中心的坐标和size。坐标的损失采用的是平方误差损失(sum of squared error loss)。（未完待续）
唐洋|风格迁移与序列模型研究	| 1. 风格迁移：将一副图片的风格迁移到另一幅新的图片中。a. 使用两张图片作为输入（如一张毕加索的图S，一张普通照片C）生成一张新的图片G；b. 风格迁移需要定义它的损失函数，内容损失L_content和风格损失L_style，整体损失为L=αL_content(C, G) + βL_style(S, G)； c. 有了输入和损失函数，就可以来训练网络了，S和C都是已知的，那G怎么初始化呢？一般采用随机数来填充整幅图像；d. 那么内容损失函数L_content具体是怎么定义呢？最简单的，取两幅图像像素差值的二范数。；e. L_style如何定义呢？这里公式有点复杂，用文字描述就是单独计算S的通道之间像素相关性（像素值相乘）、G的通道之间像素相关性（像素值相乘），之后作差，求Frobenius范数。；有了输入、初始化、损失，就可以使用优化方法对损失函数进行优化了。2. 序列模型：学习了RNN及其变种。a. 序列模型偏向于NLP、语音等方面；b. 首先是RNN网络，相比于标准的层级神经网路，RNN可以处理输入数据长度和输出数据长度不同的情况；不能在文本的不同位置共享已学得的特征。但是RNN不能利用后续的信息，在文本处理方面会有一定的局限性，比如Name Entity Recognition。而且RNN不能处理梯度消失的问题，当RNN层数很深的时候，反向传播时，后面的层，不能去影响前面的层的参数。；c. GRU网络，可以说它解决了RNN梯度消失的问题，它引入了C(memory cell)来记忆和更新门(gamma_u)来控制是否更新C或者使用old_C。；d. LSTM网络，GRU网络是LSTM的简化版本，后者多了遗忘门(gamma_f)和输出门(gamma_o)，使用gamma_u和gamma_f来控制是否更新C，所以GRU更适合搭建复杂网络，相比之下GRU搭建的网络参数会比较少。；e. BRNN(Bidirectional RNN)，在RNN的基础上增加了一个反向的RNN，正因为有了双向，所以使得RNN可以使用整段文本的信息，不过这一般需要等待文字/语音输入完毕，不适合于实时系统。；f. Deep RNNs，使用RNN、GRU、LSTM作为基本单元，横向、纵向地去搭建更深的网络以完成更复杂的任务。
肖宇|	python学习，opencv的学习|	花一天学习重温了python的大概语法；开始学习opencv在python下的使用，主要是才开始就只是学习了一些基础概念，感觉还是对python的很多科学计算的库不是很熟悉，看书看到示例代码里面引用一些库都感觉到很陌生。
帅张	|ransac	|1.	ransac 算法实现的过程：a)	记模型需要的最小样本数为 n；b)	采 n 个样本点，计算模型；c)	找到小于误差阈值的点集，其大小记为 m；d)	迭代k次，找到 m 最大时对应的模型，其参数为最优参数。2.	ransac 是怎么根据正确数据出现的概率去随机选取抽样数据？a)	给出鲁棒性的概率t，计算为达到正确概率的迭代次数 k 的最小值；b)	怎么得到内点概率t的鲁棒值？3.	大数定律是怎么体现的？a)	迭代次数越多，得到正确模型或全是内点的可能性越大。4.	为什么说ransac是用内点优化的问题？a)	先找到小于误差阈值的点集，即 inliers ，再用最小二乘法
