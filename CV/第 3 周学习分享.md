时间：2019年4月8日 ~ 2019年4月14日

学习人|学习任务|学习心得
------ | ------ | ------ 
安军刚  |零样本学习| Few-show Learing:A Survey
唐洋 | YOLO & Attention | 这周准备了3场笔试，所以学习新知识的时间不多。主要将Andrew Ng的深度学习课程的最后一节序列模型和注意力机制学完了，同时回顾了一下前面学习的YOLO算法，下面做一个总结。（文字过多，放在本文稿最后）。
朱俊| 目标追踪算法 | 最近一直在做导师的项目，主要是用有效的目标追踪算法针对我们的数据，进行多目标的追踪。这周主要在进行一些debug的工作，配合其他人工作。针对自己数据，得写一个衡量追踪效果的指标，这就是第三周的学习内容。
李钊 | 三维重建&CNN手写数字识别 | 这周导师汇报加写一篇综述，浪费时间比较多，主要做了两件事，一是分别用深度相机和双目摄像头进行三维重建，二是用CNN算法做手写数字识别实验。我在CSDN上写了几篇博客，比较费劲但是我觉得博客上也算是一种积累。还有就是一个问题想大家一起讨论一下，有些不太重要的杂事总是影响自己的学习时间以至于这周深度学习进展很是缓慢，有什么方法的话请留言给我。邮箱328045930@qq.com我的CSDN链接https://blog.csdn.net/Legend_of_Dagger_Lee
安静 |Fast RCNN 与two_stage总结|关于two_stage的总结（详情下方文字）也看了EAST论文，比较多不懂，用EAST跑天池数据的时候发生poly in wrong dection的错误，导致一部分数据不能跑，看了poly的代码还是没搞明白明明是一样顺序的坐标为什么面积有的正有的负？期待留言
Ada | 图像分类 | 这周只有一天的休息时间，在训练的时候，遇到数据不均衡的问题，尝试了下面两个方法：1、设置多个loss 2、把好的数据筛选出来，在好的数据上予以训练。目前数据在跑，结果还没出来。
568 | RCNN系列 | 下面放总结

---
## 唐洋的总结 ##
1. YOLO (v1）：

- YOLO算法，首先将图像网格化，然后将目标按中心所在位置分配给所在格子，然后利用卷积网络的参数共享特性，只需要一次卷积就可以得出结果，加速计算，能做到实时。
- 对每个格子都预测B个bounding boxes，每个bounding box都包含5个预测值：x,y,w,h和confidence，在原文中作者取S=7，B=2.
- 为了解决有很多检测框的问题，h和confidence，保留最大的，其他的删除。
- 为了解决有多个目标出现在同一个grid里的情况，通过预先设置Anchor box模板，来解决，假设会有2个目标同时出现在同一个grid中，行人和汽车，就设置两个Anchor box1和Anchor box2，同时将输出y，这里y里面的元素就会有10个了。再对于每个类别，单独运行非极大值抑制，就可以得到最后的结果。
- 如何选择anchor box：
1、可以人工的指定Anchor box的形状，使其包含训练集中的大多数样本，个数一般5-10个左右。
2、还有更好的做法，k-means算法，对形状进行聚类。

2. Attention：
Attention说白了是做一个向量加权，在NLP、语音和图像描述等方面上得到了应用。

    2.1. Attention的定义：

    - 给定一组向量集合values，以及一个向量query，attention机制是一种根据该query计算values的加权求和的机制。

    - attention的重点就是这个集合values中的每个value的“权值”的计算方法。

    - 有时候也把这种attention的机制叫做query的输出关注了（或者说叫考虑到了）原文的不同部分
   
   通过计算Attention Scores，然后利用softmax函数将其概率化。
   
    2.2. Attention的变体
   
    - soft attention、global attention、动态attention
    - Hard attention
    - local attention
    - 静态attention
    - 强制前向attention
    - self attention
    - key-value attention
    - multi-head attention
    
## 安静的总结<br>
<br>
## 1.继续看了Fast RCNN<br>
<br>
## 2.Two-stage总结<br>
<br>
### 常见算法：<br>
R-CNN 、Fast R-CNN 、 Faster R-CNN 、Faster R-CNN变种<br>
<br>
### 基本流程：<br>
    * 输入-->CNN网络提取特征-->RPN网络对候选框进行提取筛选-分类层对候选框内物体进行分类，回归层对候选框的进行精细调整.<br>
    * Input -->Conv&pooling(一主干网络 vgg、ResNet)-->Conv-->roi_pooling-->fc(全连接)-->Lcls\Lreg<br>
<br>
###核心组件<br>
* CNN网络提取特征部分<br>
我们生活中的问题大多不是线性问题，网络越深，非线性表达能力越强，能得到更为抽象的表达。越深层次的网络特征受图像最初变化越不敏感，鲁棒性越好。<br>
<br>
* RPN网络<br>
    * 区域推荐（anchor机制）<br>
        CNN得到的共享卷积层 feature map，，为了生成region proposals，我们在卷积的feature map上滑动一个小的网络,这个小网络需要输入卷积feature map的一个n乘n窗口。每个滑动窗口都映射到一个低维特征.这个特征被输入到两个全连接层中（一个box-regression层（reg），一个box-classification层（cls））。<br>
        滑动的小网络就是对特征图做一次n乘n卷积操作,定义每个锚点在滑窗的中心，在每一个滑窗位置同时预测k个区域建议。对于w ,h大小的卷积特性图（通常为           2,400），总共有w乘h乘k个锚点。<br>
        然后，经历两次1乘1卷积，得到2个分数、4个坐标，也就是之前说的分类和边框回归阶段（区分目标还是背景）。<br>
        利用真值（GroundTruth）和IOU函数进行筛选，为两种锚点分配一个正标签：<br>
        （i）与真值框有最高IOU的锚点<br>
        （ii）与任何真值框有超过0.7的IOU。<br>
        一个真值框可以将正标签分配给多个锚点。如果锚点与所有真值框的IOU比例小于0.3，则赋给它一个负标签。<br>
        既不是正或也不是负的锚点没有给训练目标做任何贡献。<br>
        最后进行汇总，通过对 两个分支的结果进行汇总，来实现对anchor的初步筛除（先剔除越界的anchor，再根据cls结果通过NMS算法去重）和 初步偏移（根据bbox reg结果），此时输出的叫 Proposal 。<br>
    * ROI_Pooling层：利用RPN网络得到的候选区域进行抠图和固定尺寸的输出<br>
                   由于proposal是对应 M * N 尺度的，所以首先使用spatial_scale参数将其映射回 feature map尺度；<br>
                   再将每个proposal对应的feature map区域水平分割为相同大小尺寸的网格；<br>
                   对网格的每一份都进行max pooling处理<br>
   
   
## 568的总结<br>
# 1 RCNN<br>
- 如何产生候选区域：Region proposal<br>
    + 是非CNN算法，用普通图像处理技术产生候选区域。<br>
    + 具体说就是seletive search（python selectivesearch有专门的轮子）<br>
    + oversegmented（所有细粒度的分隔都加到候选区域里，合并相似区域再加到候选区域中）<br>
    + 根据聚类算法迭代找<br>
- 对于每个候选区域的处理<br>
    + 先通过CNN来提取特征（可以fine-tuning技术，就是用别人训练好的图像分类网络的前面一大部分，自己根据需要改后面的部分）<br>
    + 这里的CNN也会做BBOX回归<br>
    + 通过线性SVM来判断候选区域中的物体是否目标类别的物体<br>

# 2 Fast-RCNN<br>
- 如何产生候选区域：Region proposal<br>
    + 具体内容和RCNN一样<br>
- 图片先经过一个十几层的CNN（例如VGG16、Resnet19）得到特征图<br>
- 对于每一个Region proposal，在CNN中找到对应的区域，通过RoI (Region of Interest)的Pooling层改成固定大小的特征图，具体pooling的步长要根据输入图片的大小来定<br>
- 把特征图喂入另外一个多任务CNN，既判断种类又回归输出BBOX的offsets4个值（smooth L1损失函数做bbox_offsets）<br>
- 快就快在每张图片共享前面的一个提取特征图的CNN<br>
- 两个CNN都可用预训练的图片分类CNN来进行权重初始化，但是不能初始化成一样的权重<br>

# 3 Faster-RCNN<br>
- 如何产生候选区域：通过CNN（这也是faster的原因）<br>
- 先在图片经过十几层卷积网络的特征图上搞出来一个分支专门学习如何做proposals，测试的时候直接用这个分支产生的Region proposal代替seletive search产生的。<br>
- 有了proposal之后后续处理步骤和Fast-RCNN一样<br>

# 4 Mask-RCNN<br>
- 下周见<br>
















