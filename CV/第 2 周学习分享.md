时间：2019年4月1日 ~ 2019年4月7日

学习人 | 学习任务 | 学习心得 | 参考资料
--- | --- | --- | ---
李钊|	神经网络及CNN搭建；以及对高精度三维建模方案总结	|这周主要是做一个CV的工程，对CNN搭建还没有全部完成，我分两个部分来说吧；1.首先，这段时间我要做一个项目，是一个精确建模的工程。我阅读了大量论文总结一下三维重建的一些方法a.大型场景的低精度建模方法：1多视角建模法：这种方法仅需要一台摄像机，但是需要摄像的角度位置信息。这种方法我就不赘述了。它的精度理论上可以达到厘米级别。计算成本稍微有点大。第二种方法就是双目视觉的方式，这样可以低成本的进行建模，建模的理论精度可以达到3-5毫米，但是需要对相机参数进行一些算法修正和校准。b.小型物体的精确建模：对于小型物体的建模重点一般在目标的分割和匹配算法上，但是对于工程项目来说精度也是一个指标，这里可以采用高清双目摄像头或者深度相机来进行建模，主要难度是目标的分割和多幅图像的拼接上。计算成本也是比较高。c.大范围精确建模：这里如果要求毫米级别的精度建模的话一般是三种方式。1.激光雷达：这种传感器的精度可以达到数十个微米级别，就算在建模的时候没有对参数进行修正也影响不大，但是有一个致命的问题就是成本太高。2.深度相机：深度相机按照原理一般分为结构光和近红外，这两种深度相机建模精度都比较高，但是近红外会更加高一点，稳定性也更好。这种传感器获取信息多，数据少，计算成本比较小，算法得当可以达到实时效果。3.特殊镜头的双目摄像头：这个我有所了解，但是具体没有很深入，原理还没有理解，这个下周再看看。2.这周我用python对神经网络进行搭建，python的数据结构比较熟悉了，虽然依旧出现几个错误，但是无伤大雅，一个比较可怕的事情是反向传播算法那一块我没想起来，最后还是通过对前向传播算法的反推才把这一块弄出来，本来以为理论方面没有问题，但是总是会忽略一些小的简单的事，就应该多去总结，多去实践来反馈。CNN原理我就不赘述了，在搭建CNN的时候我直接使用tensorflow了，主要可能是因为时间不是很够，下周我要从底层再把CNN搭建一遍，从原理上吃透它。这周说实话由于清明小长假，工作量不是特别大，自己也在第二周有所懈怠，要勤于自勉。
唐洋|	准备笔试 & NLP基础	| 1、图像基础复习： ①：相机模型参数，相机畸变系数及矫正;相机模型参数分为内参与外参，内参有焦距f、像素宽度dx和像素高度dy、相机主点u0、v0，外参有R和T。畸变分为径向畸变（桶型、枕型）和切向畸变，前者有k1、k2、k3、k4 4个系数，后者有p1、p2 2个系数。矫正公式略。②：常用边缘检测算子，一阶算子：Sobel、Prewitt、Robert、canny；二阶算子：Laplacian，对噪声敏感。Sobel和Prewitt只是权值不同，效果上，Sobel要由于Prewitt，Robert是使用对角差分。其中canny是阶段性算法，分为3个阶段滤波、增强、检测，效果最好。2、NLP基础 ①：学习了Word Embedding，它包含了词与词之间的关系，将一个词用一定维度的向量来表示，作为网络的输入。②：如何训练Word Embedding，通常采用context-target pairs的方法，Context的选定有：Last 4 words、4 words on left & right、Last 1 word、Nearby 1 word，通过这种方式来构造监督学习的样本。现成的方案有基于CBOW 的 Word2Vec方法和基于Skip-Gram的Word2Vec方法，CBOW方案是使用周围的词来预测中间的词，Skip-Gram是使用中间的词来预测周围的词，Skip-Gram使用的要多一点。但Skip-Gram中使用softmax进行分类，针对大数据集，softmax的分母计算较耗时，所以出现了层级softmax（二叉树）、Negative Sampling（使用1个正样本，k个负样本来组成一次迭代的样本）。 ③：GloVe：比较简单的Word Embedding方法，通过对一个公式求最小化的参数即可。④：用RNN来做情感分类，首先下载已经训练好的Word Embedding，然后将分词的结果通过Word Embedding转换为词向量，再通过搭建好的RNN来进行做情感分类。
朱俊|	最近忙着做项目，主要负责tracking这一块|	1.看了上周我的打卡文档，我发现这周基本啥正事都没做；2.非有效沟通浪费了我一整天的时间；3.输出内容不完善，增加内容，花了我一个的时间（根本原因还是源代码吃的不够熟）；4.这一周增加了下午去运动的项目，得为以后的子子孙孙考虑一下，多运动，有个好身体，找个好老婆，哈哈；5.粗读了一遍deep sort论文和代码，很多细节没有不太懂，还没有深入畸变分为径向畸变（桶型、枕型）和切向畸变，前者有k1、k2、k3、k4 4个系数，后者有p1、p2 2个系数。
帅张	|吴恩达的机器学习	|在网易云课堂上找到了吴恩达的机器学习和深度学习课程，定下来目标，参考黄海广等前人整理的文字笔记，三周内熟悉《机器学习》的必要知识。
肖宇	|python学习、图像概念	|1、这周感觉自己还是停留在python的学习上，以及图像方面的概念学习。通过python实现图像的一些简单的功能；                                                           2、刷了leetcode，加强算法编程方面的练习，主要是通过一道题，使用C和python两种语言解答，加深对语言的熟练度和理解。  
568	|实时人脸，图像分类	|首先是resnet新版本Res2Net，概括说就是通过分组卷积基础上不同支路不同位置加和，实现了计算量不变但是残差块感受野大大丰富来提高精度。其次是复现mtcnn，实际上复现难道最大的反而是最简单的pnet，因为网络浅又在前面，搞不好直接什么都认不出来。pNet要求750w张图30个epoch，其他两个Net1w张图就能搞定。其他的正在总结
安静	| 文字检测	| 这周还是让 Fast R-CNN 再飞一会 ，过去的这一周在训练EAST模型，ICDAR2015跑了10万次，并没有进行测试，loss值0.2左右。准备在MTW2018上跑，训练集坐标数据标的顺序与2015不同得改改。去学c++，awsl
赵鹏云|	YOLOv2	|YOLOv2的输入图片大小为416*416，经过5次maxpooling之后得到13*13大小的特征图，并以此特征图采用卷积做预测。13*13大小的特征图对检测大物体是足够了，但是对于小物体还需要更精细的特征图（Fine­Grained Features）。因此SSD使用了多尺度的特征图来分别检测不同大小的物体，前面更精细的特征图可以用来预测小物体。YOLOv2提出了一种passthrough层来利用更精细的特征图。YOLOv2所利用的Fine­Grained Features是26*26大小的特征图（最后一个maxpooling层的输入），对于Darknet­19模型来说就是大小为26*26*512的特征图。passthrough层与ResNet网络的shortcut类似，以前面更高分辨率的特征图为输入，然后将其连接到后面的低分辨率特征图上。前面的特征图维度是后面的特征图的2倍，passthrough层抽取前面层的每个2*2的局部区域，然后将其转化为channel维度，对于26*26*512的特征图，经passthrough层处理之后就变成了13*13*2048的新特征图（特征图大小降低4倍，而channles增加4倍，图6为一个实例），这样就可以与后面的13*13*1024特征图连接在一起形成13*13*3072的特征图，然后在此特征图基础上卷积做预测。在YOLO的C源码中，passthrough层称为reorg layer。在TensorFlow中，可以使用tf.extract_image_patches或者tf.space_to_depth来实现passthrough层。
Ada  |	图像分类	| 这周被工作所累，之前分类的结果不好，研究了混淆矩阵，清洗了数据，发现数据严重不均衡。重新做了数据，这周一边跑，一边研读有关分类的paper
