时间：2019年7月15日 ~ 2019年7月21日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
李钊 | GoogLeNet | 这周因为出差学习时间异常的少，翻译了一半GoogLeNet，上周的Alexnet还没写完代码。GoogLeNet是一种图像分类算法，论文大概读完一遍了。论文比较棒，感觉不光是算法，论文中言词都让人感觉以另一个程度的。再说GoogLeNet的算法，完全跟无脑的alexnet不一样，是另一种算法，不是那种完全靠添加多个卷积池化层来提升性能的。googlenet基本改变了以前那种固定的网络结构，改用更灵活的方式，将庞大的网络变的相对小巧的多。它做的贡献有两个，一个是使用1X1的卷积核进行升降维数，这样以最小计算成本实现。另一个是在多个尺寸上同时进行卷积再聚合,有一个filter concat模块，利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度。总之，GoogLeNet的论文还没有翻译精读完成，里面涉及的一些论文也没去好好看，因此需要把这些全部看完才能完整的评价和学习这篇论文。
七少 | python数据包基础夯实 | 笔记地址：https://github.com/xiaoxuebajie/CV_learning
sampras | 实时计算梳理 | 1.shell,awk数据编程巩固        2.Flink实时流原理学习与实战      3.视频增强和超分辨率知识的梳理
君君 | 权重节点梯度的详细推导 | 1.针对最基本的全连接+激活函数这类型的网络结构中每一个节点处反向传播时梯度的计算以及权重增量，从而能够直观理解sigmoid当激活函数时为什么会发生梯度消失的状况；2.增加对卷积层和池化层中权重节点的梯度计算及相应权重增量的推导公式。
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。

### 君君的学习笔记
图片稍后更新
