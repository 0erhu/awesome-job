时间：2019年7月15日 ~ 2019年7月21日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
李钊 | GoogLeNet | 这周因为出差学习时间异常的少，翻译了一半GoogLeNet，上周的Alexnet还没写完代码。GoogLeNet是一种图像分类算法，论文大概读完一遍了。论文比较棒，感觉不光是算法，论文中言词都让人感觉以另一个程度的。再说GoogLeNet的算法，完全跟无脑的alexnet不一样，是另一种算法，不是那种完全靠添加多个卷积池化层来提升性能的。googlenet基本改变了以前那种固定的网络结构，改用更灵活的方式，将庞大的网络变的相对小巧的多。它做的贡献有两个，一个是使用1X1的卷积核进行升降维数，这样以最小计算成本实现。另一个是在多个尺寸上同时进行卷积再聚合,有一个filter concat模块，利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度。总之，GoogLeNet的论文还没有翻译精读完成，里面涉及的一些论文也没去好好看，因此需要把这些全部看完才能完整的评价和学习这篇论文。
七少 | python数据包基础夯实 | 笔记地址：https://github.com/xiaoxuebajie/CV_learning
sampras | 实时计算梳理 | 1.shell,awk数据编程巩固        2.Flink实时流原理学习与实战      3.视频增强和超分辨率知识的梳理
君君 | 权重节点梯度的详细推导 | 1.针对最基本的全连接+激活函数这类型的网络结构中每一个节点处反向传播时梯度的计算以及权重增量，从而能够直观理解sigmoid当激活函数时为什么会发生梯度消失的状况；2.增加对卷积层和池化层中权重节点的梯度计算及相应权重增量的推导公式。PS: 详细推导公式见下方。
唐洋 | 基于树莓派的目标跟踪小车 | 算法移植成功，但是小车存在左右摇摆的情况，初步确定是树莓派处理速度达不到要求的原因。
陈壮 | 高斯过程定位| 1.高斯过程是一个非参模型，数据点越多模型参数越大，预测值服从一个分布，是一个概率模型，数据点离散，连续都可以,为了解决数据越来越多，模型参数越大的问题，提出了很多算法,下周会具体去看.
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。

### 君君的学习笔记

* 1.输出层权重梯度计算
  ![1](https://img-blog.csdnimg.cn/20190722123012578.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE5NDU1NQ==,size_16,color_FFFFFF,t_70)
  
* 2.输出层前一层隐藏层权重的梯度计算
  ![2](https://img-blog.csdnimg.cn/20190722123526271.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE5NDU1NQ==,size_16,color_FFFFFF,t_70)
  
* 3.其它隐藏层权重梯度及误差传播公式
  ![3](https://img-blog.csdnimg.cn/20190722123123183.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzE5NDU1NQ==,size_16,color_FFFFFF,t_70)

* 4.卷积层和池化层权重的梯度计算
  ...
