时间：2019年7月22日 ~ 2019年7月28日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
馒头 | 了解3D Pose Estimation | 论文分享见学习心得
sampras | 图像语义分割学习入门 | 阅读了语义分割文献综述，梳理了经典的FCN、Segnet、U-Net，Dilated Convolutions、Deeplab V1&v2、RefinNet、PSPNet、Deeplab V3 &V3+,了解了其网络结构，下一步待复现算法
七少| pytorch学习 | 更新了pytorch学习笔记：https://github.com/xiaoxuebajie/pytorch_learning
唐洋 | 商场客流量预测 | 30w条数据，4维特征，业务id，日期，时间，流量。从2015-01-01到2019-01-01的数据。因为是时序数据，所以想到用LSTM来做，但是难点在于如何去处理原始的数据，包括数据的清洗，数据的变换等，如何变成LSTM的输入格式（使用lookback，如使用前25个数据，预测第26个数据）。模型调参都比较简单，重点在于对数据的预处理，不像学tf那样，直接数据都被处理好了，只需要调用load_data()训练和测试集就都被处理好了，对于原始数据的处理真心有点难度，非常考验经验。现在的情况是模型的loss几轮迭代就不动了，用cnn+lstm也是如此。不知道是数据预处理的有问题，还是模型的问题。

> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 馒头的学习心得
#### Estimation from Monocular Images with Deep Convolutional Neural Network (ACCV 2014)
##### Summary:
They are the first to show that deep neural networks can be applied to 3D human pose estimation from single images which is the simplest way that we can come up with to estimate pose. In this paper, they give a framework consisting of two types of tasks to estimate pose, which are a joint point regression task and joint poing detection tasks. The input of both tasks are the bounding box images containing human subjects. Further more, the goal of the regression task is to estimate the positions of joint points relative to the root joint position and the aim of detection task is to classify whether one local window contains the specfic joint. Then, they use the model to test on HUMAN3.6M dataset, which has many pictures of human pose.
##### Evaluation:
In this paper, they try to apply DNN to estimating human pose. They also use transfer learning and multi-task learning. This paper is significant because of its pioneering in this specific field.

#### 3D Human Pose Estimation = 2D Pose Estimation + Matching (CVPR 2017)
##### Summary:
Instead of directly predictiong 3D pose from image, the paper explores a simple two-stage solution that reasons throuth intermediate 2D pose predictions. It basees on a key observation which is deep neural networks have good performance in 2D pose estimation. Given a 3D pose library (essentially a collection of 3D poses), they generate a large number of 2D projections. Given this training set of paired (2D, 3D) data and predictions from a 2D pose estimation algorithm, the depths from the 3D pose associated with the closest matching 2D example from the library are returned. Due to the difficulty of annotation in 3D, training datasets with 3D labels are typically collected in a lab environment, while 2D datasets tend to be more diverse. The two-stage pipeline makes use of different training sets for different stages, resulting in a system that can predict 3D poses from “in-the-wild” images and hence generalize better.
##### Evaluation:
Because it is difficult to annotate 3D human pose dataset and there has been a good performance in estimating 2D human pose, this paper proposed that they can match the 2D example to a 3D pose library. 
