时间：2019年7月1日 ~ 2019年7月7日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
安军刚 | 图像超分辨  | 图像超分辨和图像高分辨之间的区别是：图像超分辨描述是图像由小到大的一个变化过程，图像高分辨是图像本身较大的一个状态。对于图图像的超分辨任务SR通常使用比较深的卷积神经网络编码成较高分辨率的图像过程，该方向比较难的一个点是SISR单张图像超分辨在医学、天文、安防方面有广泛使用，通常都是插值重构的方案，但是这种方法有一定局限性。代码地址：https://github.com/lightningsoon/Residual-Dense-Net-for-Super-Resolution。论文地址：https://arxiv.org/abs/1802.08797。在上面的论文和代码中是以三个模块实现超分辨的单张功能，模块一是密集型残差网络RDB、模块二是局部特征混合LFF、模块三是LRL局部特征学习。因为卷积神经网络和图像中距离像素较远的关联关系较弱所以局部特征更能表达深度特征能力。整个RDN主要包括4个部分：隐藏特征提取网络（SFENet），残差密集模块（RDBs），密集特征融合（DFF），和最后的上采样网络（UPNet）。
唐洋 | SVM学习 | 参考资料《统计学习方法》第七章, July的博客[支持向量机通俗导论](http://vdisk.weibo.com/s/zrFL6OXKgnlcp)，*后者是对前者的详细补充*。SVM分为线性可分SVM，线性（软间隔）SVM和非线性SVM，其中大量使用**对偶问题与原问题**的转换，通过满足**KKT条件**，来讲对偶问题的解对应到原问题的解。SMO算法是采用启发式的方法来快速寻找到需要优化的`alpha pair`，首先固定一个`alpha`（违反KKT条件最厉害的那个），然后通过启发式方法寻找下一个`alpha`（使`abs(E1-E2)`最大的那个）。计算出所有的alpha之后，就可以计算出w和b了，alpha>0的就是支持向量。
我曾 | CNN初步 | 本周对CNN进行初步学习，分别通过pytorch和tensorflow 完成两层 CNN，代码：https://github.com/xiaoxuebajie/deeplearning/tree/master/CNN
sampras| NLP 入门 | When deep learning met code search 论文阅读，对NLP方向许多基础不是很好，就去B站学习了带字幕的cs224视频，周末又去做了课程作业
杨志强|学习《动手学深度学习》卷积神经网络部分|学习卷积神经网络的网络结构，其中有LeNet,AlexNet,VGGNet,GoogleNet,ResNet
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
