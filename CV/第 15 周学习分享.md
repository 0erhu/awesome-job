时间：2019年7月1日 ~ 2019年7月7日

学习人|学习任务|学习心得和参考资料
------ | ------ | ------ 
安军刚 | 图像超分辨  | 图像超分辨和图像高分辨之间的区别是：图像超分辨描述是图像由小到大的一个变化过程，图像高分辨是图像本身较大的一个状态。对于图图像的超分辨任务SR通常使用比较深的卷积神经网络编码成较高分辨率的图像过程，该方向比较难的一个点是SISR单张图像超分辨在医学、天文、安防方面有广泛使用，通常都是插值重构的方案，但是这种方法有一定局限性。代码地址：https://github.com/lightningsoon/Residual-Dense-Net-for-Super-Resolution。论文地址：https://arxiv.org/abs/1802.08797。在上面的论文和代码中是以三个模块实现超分辨的单张功能，模块一是密集型残差网络RDB、模块二是局部特征混合LFF、模块三是LRL局部特征学习。因为卷积神经网络和图像中距离像素较远的关联关系较弱所以局部特征更能表达深度特征能力。整个RDN主要包括4个部分：隐藏特征提取网络（SFENet），残差密集模块（RDBs），密集特征融合（DFF），和最后的上采样网络（UPNet）。
唐洋 | SVM学习 | 参考资料《统计学习方法》第七章, July的博客[支持向量机通俗导论](http://vdisk.weibo.com/s/zrFL6OXKgnlcp)，*后者是对前者的详细补充*。SVM分为线性可分SVM，线性（软间隔）SVM和非线性SVM，其中大量使用**对偶问题与原问题**的转换，通过满足**KKT条件**，来讲对偶问题的解对应到原问题的解。SMO算法是采用启发式的方法来快速寻找到需要优化的`alpha pair`，首先固定一个`alpha`（违反KKT条件最厉害的那个），然后通过启发式方法寻找下一个`alpha`（使`abs(E1-E2)`最大的那个）。计算出所有的alpha之后，就可以计算出w和b了，alpha>0的就是支持向量。
我曾 | CNN初步 | 本周对CNN进行初步学习，分别通过pytorch和tensorflow 完成两层 CNN，代码：https://github.com/xiaoxuebajie/deeplearning/tree/master/CNN
sampras| NLP 入门 | When deep learning met code search 论文阅读，对NLP方向许多基础不是很好，就去B站学习了带字幕的cs224视频，周末又去做了课程作业
杨志强|学习《动手学深度学习》|学习卷积神经网络的网络结构，其中有LeNet,AlexNet,VGGNet,GoogleNet,ResNet
君君 | 传统图像分割及人脸检测 | 1.了解区域生长算法以及分水岭算法原理；2.前景分割：学习Graph Cuts（最小割算法）和GrabCut（混合高斯模型+K-means聚类+Graph Cuts）分割算法原理；3.使用Haar级联分类器，利用多个弱分类器加权构造一个强分类器用于人脸检测。
陈壮壮|阅读论文 Feature selection for position estimation using an omnidirectional camera|1.feature extraction,提取的特征Y与位置X理想情况下定义一个函数F(X)=Y 2.高斯模型处理Y为机器人的位置，X为在Y点的观测值，来预测准确的Y。
李钊 |alexnet|这周翻译复现AlexNet，首先翻译了AlexNet的论文，这个网络基本上是由8个层级级联而成，前五个卷积层后三个全连接层。论文主要论述了几种取巧的策略，虽然感觉不太高明，但是论文主要是显示它的效果。全文基本没有任何理论推导，仅仅是一些实验发现的策略，这让人感觉缺点什么。论文近一小半的篇章是论述效果，在论文翻译中最大的收获是需要有一个论文的广度积累量，文中出了应用CNN外其他部分基本都是其他论文的结论。更有甚者，有些部分直接用简单粗暴的方式替代其他论文算法，并美其名曰减少训练成本。Alexnet的复现可以说也不是非常容易，由于论文中写的不是特别详细，在部分细节地方没做好，通过对GitHub上代码的观察，我暂时没怎么看明白，下周把这一块再做一下。接下来开始培养一下读论文，思考以及复现的能力。
> 注：大家打卡时，为了方便自己和拯救他人，请注意**格式美观**，每段用心编辑的文字，都代表了我们的学习态度。如果表格中无法很好的显示格式，可以在文档后附上打卡内容，如下

### 张三的学习心得
这是示例，更新之后请将这段删除。
